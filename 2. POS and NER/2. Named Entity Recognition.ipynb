{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Name Entity Recognition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "def show_ents(doc):\n",
    "    \"\"\"Displays entities info.\"\"\"\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))\n",
    "    else:\n",
    "        print('No named entities found.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Named Entities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washington, DC - GPE - Countries, cities, states\n",
      "next May - DATE - Absolute or relative dates or periods\n",
      "the Washington Monument - ORG - Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('May I go to Washington, DC next May to see the Washington Monument?')\n",
    "show_ents(doc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 dollars - MONEY - Monetary values, including unit\n",
      "Microsoft - ORG - Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp('Can I please borrow 500 dollars from you to buy some Microsoft stock?')\n",
    "show_ents(doc2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Entity annotations\n",
    "`Doc.ents` are token spans with their own set of annotations.\n",
    "<table>\n",
    "<tr><td>`ent.text`</td><td>The original entity text</td></tr>\n",
    "<tr><td>`ent.label`</td><td>The entity type's hash value</td></tr>\n",
    "<tr><td>`ent.label_`</td><td>The entity type's string description</td></tr>\n",
    "<tr><td>`ent.start`</td><td>The token span's *start* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.end`</td><td>The token span's *stop* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.start_char`</td><td>The entity text's *start* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.end_char`</td><td>The entity text's *stop* index position in the Doc</td></tr>\n",
    "</table>\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NER Tags\n",
    "Tags are accessible through the `.label_` property of an entity.\n",
    "<table>\n",
    "<tr><th>TYPE</th><th>DESCRIPTION</th><th>EXAMPLE</th></tr>\n",
    "<tr><td>`PERSON`</td><td>People, including fictional.</td><td>*Fred Flintstone*</td></tr>\n",
    "<tr><td>`NORP`</td><td>Nationalities or religious or political groups.</td><td>*The Republican Party*</td></tr>\n",
    "<tr><td>`FAC`</td><td>Buildings, airports, highways, bridges, etc.</td><td>*Logan International Airport, The Golden Gate*</td></tr>\n",
    "<tr><td>`ORG`</td><td>Companies, agencies, institutions, etc.</td><td>*Microsoft, FBI, MIT*</td></tr>\n",
    "<tr><td>`GPE`</td><td>Countries, cities, states.</td><td>*France, UAR, Chicago, Idaho*</td></tr>\n",
    "<tr><td>`LOC`</td><td>Non-GPE locations, mountain ranges, bodies of water.</td><td>*Europe, Nile River, Midwest*</td></tr>\n",
    "<tr><td>`PRODUCT`</td><td>Objects, vehicles, foods, etc. (Not services.)</td><td>*Formula 1*</td></tr>\n",
    "<tr><td>`EVENT`</td><td>Named hurricanes, battles, wars, sports events, etc.</td><td>*Olympic Games*</td></tr>\n",
    "<tr><td>`WORK_OF_ART`</td><td>Titles of books, songs, etc.</td><td>*The Mona Lisa*</td></tr>\n",
    "<tr><td>`LAW`</td><td>Named documents made into laws.</td><td>*Roe v. Wade*</td></tr>\n",
    "<tr><td>`LANGUAGE`</td><td>Any named language.</td><td>*English*</td></tr>\n",
    "<tr><td>`DATE`</td><td>Absolute or relative dates or periods.</td><td>*20 July 1969*</td></tr>\n",
    "<tr><td>`TIME`</td><td>Times smaller than a day.</td><td>*Four hours*</td></tr>\n",
    "<tr><td>`PERCENT`</td><td>Percentage, including \"%\".</td><td>*Eighty percent*</td></tr>\n",
    "<tr><td>`MONEY`</td><td>Monetary values, including unit.</td><td>*Twenty Cents*</td></tr>\n",
    "<tr><td>`QUANTITY`</td><td>Measurements, as of weight or distance.</td><td>*Several kilometers, 55kg*</td></tr>\n",
    "<tr><td>`ORDINAL`</td><td>\"first\", \"second\", etc.</td><td>*9th, Ninth*</td></tr>\n",
    "<tr><td>`CARDINAL`</td><td>Numerals that do not fall under another type.</td><td>*2, Two, Fifty-two*</td></tr>\n",
    "</table>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adding Named Entities\n",
    "spaCy might not recognize an entity. In that case, we can add it. For example, 'Tesla' is not recognized as an entity.\n",
    "To add it to the entities, there are three steps:\n",
    "1. Get the hash value of the entity label.\n",
    "2. Create a new entity\n",
    "3. Add the entity to the list\n",
    "\n",
    "Example:\n",
    "```\n",
    "ORG = doc.vocab.strings[u'ORG']\n",
    "new_ent = Span(doc, 0, 1, label=ORG)        # 0 and 1 represent the start and end of the token in the doc\n",
    "doc.ents = list(doc3.ents) + [new_ent]\n",
    "print(doc.ents)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U.K. - GPE - Countries, cities, states\n",
      "$6 million - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp('Tesla to build a U.K. factory for $6 million')\n",
    "show_ents(doc3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Get the hash value of the entity label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383\n"
     ]
    }
   ],
   "source": [
    "ORG = doc3.vocab.strings[u'ORG']\n",
    "print(ORG)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Create a new entity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "# Tesla starts at 0 and ends at 1\n",
    "new_ent = Span(doc3, 0, 1, label=ORG)\n",
    "print(new_ent)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Add the entity to the list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "(Tesla, U.K., $6 million)"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3.ents = list(doc3.ents) + [new_ent]\n",
    "doc3.ents"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla - ORG - Companies, agencies, institutions, etc.\n",
      "U.K. - GPE - Countries, cities, states\n",
      "$6 million - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adding Named Entities to All Matching Spans\n",
    "What if we want to tag *all* occurrences of \"Tesla\"? In this section we show how to use the PhraseMatcher to identify a series of spans in the Doc:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first - ORDINAL - \"first\", \"second\", etc.\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp('Our company plans to introduce a new vacuum cleaner. '\n",
    "          'If successful, the vacuum cleaner will be our first product.')\n",
    "show_ents(doc4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating patterns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "[(4452177204818730156, 7, 9), (4452177204818730156, 14, 16)]"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "phrase_list = ['vacuum cleaner', 'vacuum-cleaner']\n",
    "phrase_patterns = [nlp(text) for text in phrase_list]\n",
    "matcher.add('newProduct', phrase_patterns)\n",
    "\n",
    "matches = matcher(doc4)\n",
    "matches"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating spans\n",
    "Ee create Spans from each match, and create named entities from the same spans."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vacuum cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "vacuum cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "first - ORDINAL - \"first\", \"second\", etc.\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "PROD = doc.vocab.strings['PRODUCT']\n",
    "new_ents = [Span(doc4, match[1], match[2], label=PROD) for match in matches]\n",
    "doc4.ents = list(doc4.ents) + new_ents\n",
    "show_ents(doc4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Counting Entites"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 entities label as 'MONEY': [5 thousand dollars, 4 thousand dollars]\n"
     ]
    }
   ],
   "source": [
    "doc5 = nlp('Apple owe him 5 thousand dollars. Last time was it was 4 thousand dollars.')\n",
    "\n",
    "entities5 = [ent for ent in doc5.ents if ent.label_ == 'MONEY']\n",
    "print(f'{len(entities5)} entities label as \\'MONEY\\': {entities5}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Incorrect Entities\n",
    "The categorization of the name \"Becaye\" as an organization (ORG) entity by spaCy's named entity recognition (NER) model may be due to its default behavior and the context in which the word appears. Since \"Becaye\" is not a commonly recognized entity or personal name, the model might not have enough information to accurately classify it. Training a custom NER model or fine-tuning the existing one with domain-specific data can improve entity recognition accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Becaye - ORG - Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "doc6 = nlp('Becaye is a human.')\n",
    "show_ents(doc6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Noun Chunks\n",
    "Noun chunks refer to contiguous noun phrases within a sentence.  noun phrase consists of a noun and any accompanying words or modifiers that provide additional information about the noun. Noun chunks are commonly used to identify and extract meaningful noun-based units from text.\n",
    "\n",
    "For example, consider the sentence: \"The big brown dog chased the squirrel up the tree.\" The noun chunks in this sentence would be:\n",
    "\n",
    "* \"The big brown dog\"\n",
    "* \"the squirrel\"\n",
    "* \"the tree\"\n",
    "\n",
    "\n",
    "### `noun_chunks` components:\n",
    "<table>\n",
    "<tr><td>`.text`</td><td>The original noun chunk text.</td></tr>\n",
    "<tr><td>`.root.text`</td><td>The original text of the word connecting the noun chunk to the rest of the parse.</td></tr>\n",
    "<tr><td>`.root.dep_`</td><td>Dependency relation connecting the root to its head.</td></tr>\n",
    "<tr><td>`.root.head.text`</td><td>The text of the root token's head.</td></tr>\n",
    "</table>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text                  Root text           Root dep           Root head Text\n",
      "Autonomous cars       cars                nsubj              shift\n",
      "insurance liability   liability           dobj               shift\n",
      "manufacturers         manufacturers       pobj               toward\n"
     ]
    }
   ],
   "source": [
    "doc7 = nlp(\"Autonomous cars shift insurance liability toward manufacturers.\")\n",
    "\n",
    "print(f'Text{\"\":{17}} Root text{\"\":{10}} Root dep{\"\":{10}} Root head Text')\n",
    "\n",
    "for chunk in doc7.noun_chunks:\n",
    "    print(f'{chunk.text:{21}} {chunk.root.text:{19}} {chunk.root.dep_:{18}} {chunk.root.head.text}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
